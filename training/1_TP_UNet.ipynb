{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28820,"status":"ok","timestamp":1701862629247,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"XrcKeAO3sN74","outputId":"dd88a190-f708-486f-f188-7cb3b3307cd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1701862632447,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"PgbexGdNr7zw","outputId":"85fb99f5-6c4b-4db3-abaf-3277c83861de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Dec  6 11:37:12 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1701862637942,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"WsVd5oRzsBA7","outputId":"1b5ee27e-989e-4603-b44f-65a98c84f682"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4616,"status":"ok","timestamp":1701862647446,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"cyIVbkgWVrQk"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import glob\n","import nibabel as nib\n","import cv2\n","import imageio\n","from tqdm.notebook import tqdm\n","from ipywidgets import *\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","from tensorflow import keras\n","import random\n","import matplotlib.pyplot as plt\n","\n","from skimage import data, color\n","from skimage.transform import rescale, resize, downscale_local_mean\n","import skimage.transform  as sktf\n"]},{"cell_type":"markdown","metadata":{"id":"AyYndE3QWVdn"},"source":["DATA TRAINING LITS"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":375,"status":"ok","timestamp":1701862651744,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"Ci-1Rh700SVQ"},"outputs":[],"source":["import cv2\n","def rotate_image(ct, label):\n","  ct = cv2.rotate(ct, cv2.ROTATE_90_CLOCKWISE)\n","  label = cv2.rotate(label, cv2.ROTATE_90_CLOCKWISE)\n","  return ct, label"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1701862652945,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"I2xqIshx6fBu"},"outputs":[],"source":["import cv2\n","def flip_image(ct, label):\n","  axis = random.randint(-1, 1)\n","  ct = cv2.flip(ct, axis)\n","  label = cv2.flip(label, axis)\n","  return ct, label"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1701862660537,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"3PVCuKFWCEAW"},"outputs":[],"source":["import random\n","w, h = 128, 128\n","batch_size = 16\n","\n","# Dataset va Dataloader\n","\n","# Dung de tao toan bo du lieu va load theo batch\n","class Dataset:\n","    def __init__(self, image_path, mask_path, w, h):\n","        # the paths of images\n","        self.image_path = image_path\n","        # the paths of segmentation images\n","        self.mask_path = mask_path\n","\n","        self.w = w\n","        self.h = h\n","\n","    def __getitem__(self, i):\n","\n","        image = np.load(self.image_path[i])\n","        mask =  np.load(self.mask_path[i])\n","        return image, mask\n","\n","class Dataloader(tf.keras.utils.Sequence):\n","    def __init__(self, dataset, batch_size,shape, shuffle=False, data_transform=None):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.shape = shape\n","        self.indexes = np.arange(self.shape)\n","        self.data_transform = data_transform\n","        self.on_epoch_end()\n","\n","    def __getitem__(self, i):\n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        data = []\n","        for j in range(start, stop):\n","            if self.data_transform:\n","              num = random.randint(0, 1)\n","              #### original image\n","              # num = 0\n","              _image,_label = self.dataset[j]\n","              data.append((_image,_label))\n","              if num == 0:\n","                ### rotate image\n","                _image_RT, _label_RT = rotate_image(_image, _label)\n","                _image_RT = np.expand_dims(_image_RT, -1)\n","                _label_RT = np.expand_dims(_label_RT, -1)\n","                data.append((_image_RT,_label_RT))\n","              else:\n","                _image_FL, _label_FL = flip_image(_image, _label)\n","                _image_FL = np.expand_dims(_image_FL, -1)\n","                _label_FL = np.expand_dims(_label_FL, -1)\n","                data.append((_image_FL,_label_FL))\n","            else:\n","              _image,_label = self.dataset[j]\n","              data.append((_image,_label))\n","\n","        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","\n","        return tuple(batch)\n","\n","    def __len__(self):\n","        return len(self.indexes) // self.batch_size\n","\n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.indexes = np.random.permutation(self.indexes)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701862663464,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"LzeBE52_gp0Z"},"outputs":[],"source":["path_train_ct_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Train/ct.txt\"\n","path_train_label_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Train/label.txt\"\n","\n","path_validate_ct_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Validate/ct.txt\"\n","path_validate_label_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Validate/label.txt\"\n","\n","path_test_ct_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Test/ct.txt\"\n","path_test_label_txt = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Path/Test/label.txt\""]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2551,"status":"ok","timestamp":1701862668191,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"jkVXbubB0E93"},"outputs":[],"source":["# for read ct training dataset\n","image_train = []\n","with open(path_train_ct_txt, \"r\") as input:\n","    image_train = input.read().split(',')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1701862670794,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"U02KOGnx0dgv","outputId":"296c7a10-f4dc-4715-95b7-14b3a42ba465"},"outputs":[{"name":"stdout","output_type":"stream","text":["5514\n"]}],"source":["print(len(image_train))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":513,"status":"ok","timestamp":1701862671303,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"uUqDYjZj0RuK"},"outputs":[],"source":["# for read label training dataset\n","mask_train = []\n","with open(path_train_label_txt, \"r\") as input:\n","    mask_train = input.read().split(',')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1701862672288,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"MPx-J6aA0fim","outputId":"8204e0a6-6b63-4dd4-a8c7-6efb57d77245"},"outputs":[{"name":"stdout","output_type":"stream","text":["5514\n"]}],"source":["print(len(mask_train))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1701848555024,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"Ci8mE74P0kVq","outputId":"7a7e694b-f00a-4a18-ea92-854c271ee84f"},"outputs":[{"name":"stdout","output_type":"stream","text":["689\n"]}],"source":["# for read ct validate dataset\n","image_validate = []\n","with open(path_validate_ct_txt, \"r\") as input:\n","    image_validate = input.read().split(',')\n","\n","print(len(image_validate))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1701848557742,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"fDqheAlP0q1e","outputId":"730939e4-3177-48ac-a8ea-638e79e9113a"},"outputs":[{"name":"stdout","output_type":"stream","text":["689\n"]}],"source":["# for read label validate dataset\n","mask_validate = []\n","with open(path_validate_label_txt, \"r\") as input:\n","    mask_validate = input.read().split(',')\n","\n","print(len(mask_validate))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111212,"status":"ok","timestamp":1701848671287,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"RVLZrw1ibmHR","outputId":"888672e1-0ef9-4759-9ff8-984ca7c5e6f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 128, 128, 1) (32, 128, 128, 1)\n","5514\n","689\n"]}],"source":["# from sklearn.model_selection import train_test_split\n","# image_train, image_validate, mask_train, mask_validate = train_test_split(path_train_list, path_train_mask_list, test_size=0.2,random_state= 45)\n","# image_validate, image_test, mask_validate, mask_test = train_test_split(image_validate, mask_validate, test_size=0.5,random_state= 45)\n","\n","train_dataset = Dataset(image_train, mask_train, w, h)\n","validate_dataset = Dataset(image_validate, mask_validate, w, h)\n","# test_dataset = Dataset(image_test, mask_test, w, h)\n","\n","train_loader = Dataloader(train_dataset, batch_size, shape=len(image_train), shuffle=True, data_transform=True)\n","validate_loader = Dataloader(validate_dataset, batch_size, shape=len(image_validate), shuffle=True, data_transform=True)\n","\n","train_steps = len(image_train)//batch_size\n","valid_steps = len(image_validate)//batch_size\n","\n","x, y = train_loader.__getitem__(1)\n","print(x.shape, y.shape)\n","print(len(image_train))\n","print(len(image_validate))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Nrz-Yi3fWd6"},"outputs":[],"source":["# for ct training dataset and label training\n","# with open(path_train_ct_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(image_train)):\n","#         if(index != (len(image_train)-1)):\n","#           strr = image_train[index] +\",\"\n","#         else:\n","#           strr = image_train[index]\n","#         output.write(strr)\n","\n","\n","# with open(path_train_label_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(mask_train)):\n","#       if(index != (len(mask_train)-1)):\n","#         strr = mask_train[index] +\",\"\n","#       else:\n","#         strr = mask_train[index]\n","#       output.write(strr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arkSV6TTgwTq"},"outputs":[],"source":["# for ct validate dataset and label validate\n","# with open(path_validate_ct_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(image_validate)):\n","#         if(index != (len(image_validate)-1)):\n","#           strr = image_validate[index] +\",\"\n","#         else:\n","#           strr = image_validate[index]\n","#         output.write(strr)\n","\n","\n","# with open(path_validate_label_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(mask_validate)):\n","#         if(index != (len(mask_validate)-1)):\n","#           strr = mask_validate[index] +\",\"\n","#         else:\n","#           strr = mask_validate[index]\n","#         output.write(strr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4OO969agm4W"},"outputs":[],"source":["# for ct test dataset and label test\n","# with open(path_test_ct_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(image_test)):\n","#         if(index != (len(image_test)-1)):\n","#           strr = image_test[index] +\",\"\n","#         else:\n","#           strr = image_test[index]\n","#         output.write(strr)\n","\n","\n","# with open(path_test_label_txt, \"w\") as output:\n","#     strr =\"\"\n","#     for index in range(len(mask_test)):\n","#         if(index != (len(mask_test)-1)):\n","#           strr = mask_test[index] +\",\"\n","#         else:\n","#           strr = mask_test[index]\n","#         output.write(strr)\n"]},{"cell_type":"markdown","metadata":{"id":"oJBFItO4bbIc"},"source":["#Model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1701862691617,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"AifUjHAvhsc5"},"outputs":[],"source":["def ConvBlock(filters,\n","               kernel_size,\n","               strides=(1, 1),\n","               padding='valid',\n","               activation=None,\n","               kernel_initializer='he_uniform',\n","               dropout=None,\n","               use_batchnorm=True):\n","    def wrapper(input_tensor):\n","        conv = layers.Conv2D(filters=filters,\n","                             kernel_size=kernel_size,\n","                             strides=(1, 1),\n","                             padding=padding,\n","                             kernel_initializer=kernel_initializer\n","                            )(input_tensor)\n","        if use_batchnorm:\n","            conv = layers.BatchNormalization()(conv)\n","        if activation:\n","            conv = layers.Activation(activation)(conv)\n","\n","        conv = layers.Conv2D(filters=filters,\n","                             kernel_size=kernel_size,\n","                             strides=(1, 1),\n","                             padding=padding,\n","                             kernel_initializer=kernel_initializer\n","                            )(conv)\n","        if use_batchnorm:\n","            conv = layers.BatchNormalization()(conv)\n","        if activation:\n","            conv = layers.Activation(activation)(conv)\n","\n","        if 0 < dropout <= 1:\n","            conv = layers.Dropout(dropout)(conv)\n","        return conv\n","\n","    return wrapper\n","\n","\n","def AttentionBlock(inter_filters,name=None):\n","    def wrapper(x,gating):\n","        shape_x = K.int_shape(x)        # (1, 128, 128, 128)\n","        shape_g = K.int_shape(gating)   # (1, 64, 64, 64)\n","\n","        theta_x = layers.Conv2D(inter_filters,(2,2),strides=(2,2),padding='same')(x)    # (1, 64, 64, 128)\n","        phi_g   = layers.Conv2D(inter_filters,(1,1),padding='same')(gating) # (1, 64, 64, 128)\n","\n","        concate_xg  = layers.add([theta_x,phi_g])   # (1, 64, 64, 128)\n","        relu_xg     = layers.Activation('relu')(concate_xg) # (1, 64, 64, 128)\n","        psi         = layers.Conv2D(1,(1,1),padding='same')(relu_xg)    # (1, 64, 64, 1)\n","        sigmoid_xg  = layers.Activation('sigmoid')(psi) # (1, 64, 64, 1)\n","        up_psi      = layers.UpSampling2D((shape_x[1]//shape_g[1],shape_x[2]//shape_g[2]),\n","                                          name=f'{name}_coefficient' if name else None)(sigmoid_xg)  # (1, 128, 128, 1)\n","        up_psi      = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n","                            arguments={'repnum': shape_x[3]})(up_psi)   # (1, 128, 128, 128)\n","        y = layers.multiply([up_psi, x])    # (1, 128, 128, 128)\n","\n","        result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)   # (1, 128, 128, 128)\n","        result_bn = layers.BatchNormalization(name=name)(result) # (1, 128, 128, 128)\n","\n","        return result_bn\n","\n","    return wrapper\n","\n","\n","def TritentionBlock(inter_filters,name=None):\n","    def wrapper(x,lower_gate, upper_gate):\n","        shape_x = K.int_shape(x)\n","        shape_lg = K.int_shape(lower_gate)\n","        shape_ug = K.int_shape(upper_gate)\n","\n","        theta_x = layers.Conv2D(inter_filters, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n","        phi_lg  = layers.Conv2DTranspose(inter_filters, kernel_size=(1,1), strides=(2,2), padding='same')(lower_gate)\n","        phi_ug  = layers.Conv2D(inter_filters, kernel_size=(2,2), strides=(2,2), padding='same')(upper_gate)\n","\n","        concate_xlg = layers.add([theta_x, phi_lg])\n","        concate_xug = layers.add([theta_x, phi_ug])\n","\n","        relu_xlg    = layers.Activation('relu')(concate_xlg)\n","        relu_xug    = layers.Activation('relu')(concate_xug)\n","\n","        conv_xlg    = layers.Conv2D(inter_filters/2, kernel_size=(1,1), strides=(1,1), padding='same')(relu_xlg)\n","        conv_xug    = layers.Conv2D(inter_filters/2, kernel_size=(1,1), strides=(1,1), padding='same')(relu_xug)\n","\n","        concate_xlu = layers.add([conv_xlg, conv_xug])\n","        relu_xlu    = layers.Activation('relu')(concate_xlu)\n","        conv_xlu    = layers.Conv2D(1, kernel_size=(1,1), strides=(1,1), padding='same')(relu_xlu)\n","        sigmoid_xlu = layers.Activation('sigmoid', name=f'{name}_coefficient' if name else None)(conv_xlu)\n","        up_xlu      = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n","                            arguments={'repnum': shape_x[-1]})(sigmoid_xlu)\n","        y = layers.multiply([up_xlu, x])\n","\n","        result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n","        result_bn = layers.BatchNormalization(name=name)(result)\n","\n","        return result_bn\n","\n","    return wrapper\n","DEPTH = 4\n","\n","def TritentionUNet(input_shape,num_classes=1,dropout_rate=0.0,batch_norm=True,activation='relu',name='tri_unet'):\n","    features = 64\n","    skip_connections = []\n","\n","    inputs = layers.Input(input_shape)\n","    x = inputs\n","\n","    # Downsampling layers\n","    for i in range(DEPTH):\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","        skip_connections.append(x)\n","        x = layers.MaxPool2D((2,2))(x)\n","        features = features*2\n","\n","    # Bottom layers\n","    x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","    skip_connections.append(x)\n","\n","    # Upsampling layers\n","    for i in reversed(range(DEPTH)):\n","        features = features/2\n","        if i != 0:\n","            att = TritentionBlock(features,name='tritention_'+str(i))(skip_connections[i],skip_connections[i+1],skip_connections[i-1])\n","        else:\n","            att = AttentionBlock(features,name='attention_'+str(i))(skip_connections[i],skip_connections[i+1])\n","\n","        x = layers.Conv2DTranspose(features,(2,2),strides=(2,2),padding='same')(x)\n","        x = layers.Activation(activation)(x)\n","        x = layers.concatenate([x, att], axis=-1)\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","\n","    # Model head\n","    conv_final = layers.Conv2D(num_classes, kernel_size=(1,1),padding='same')(x)\n","    if batch_norm:\n","        conv_final = layers.BatchNormalization(axis=-1)(conv_final)\n","    conv_final = layers.Activation('sigmoid')(conv_final)\n","    model = keras.models.Model(inputs, conv_final, name=name)\n","\n","    return model\n","\n","\n","def UNet(input_shape,num_classes=1,dropout_rate=0.0,batch_norm=True,activation='relu',name='unet'):\n","    features = 64\n","    skip_connections = []\n","\n","    inputs = layers.Input(input_shape)\n","    x = inputs\n","\n","    # Downsampling layers\n","    for i in range(DEPTH):\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","        skip_connections.append(x)\n","        x = layers.MaxPool2D((2,2))(x)\n","        features = features*2\n","\n","    # Bottom layers\n","    x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","\n","    # Upsampling layers\n","    for i in reversed(range(DEPTH)):\n","        features = features/2\n","        x = layers.Conv2DTranspose(features,(2,2),strides=(2,2),padding='same')(x)\n","        x = layers.Activation(activation)(x)\n","        x = layers.concatenate([x, skip_connections[i]], axis=-1)\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","\n","    # Model head\n","    conv_final = layers.Conv2D(num_classes, kernel_size=(1,1),padding='same')(x)\n","    if batch_norm:\n","        conv_final = layers.BatchNormalization(axis=-1)(conv_final)\n","    conv_final = layers.Activation('sigmoid')(conv_final)\n","    model = keras.models.Model(inputs, conv_final, name=name)\n","\n","    return model\n","\n","def TP_UNet(input_shape,num_classes=1,dropout_rate=0.0,batch_norm=True,activation='relu',name='para_unet'):\n","    features = 64\n","    skip_connections = []\n","    #paramid_down = []\n","    paramid_up = []\n","    paramid_down = []\n","    futures_paramid_up = []\n","    futures_paramid_down = []\n","    inputs = layers.Input(input_shape)\n","    x = inputs\n","\n","    # Downsampling layers\n","    for i in range(DEPTH):\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","        skip_connections.append(x)\n","        paramid_down.append(x)\n","        futures_paramid_down.append(features)\n","        x = layers.MaxPool2D((2,2))(x)\n","        features = features*2\n","\n","    # Bottom layers\n","    x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","    skip_connections.append(x)\n","\n","    # Upsampling layers\n","    for i in reversed(range(DEPTH)):\n","        features = features/2\n","        if i != 0:\n","            att = TritentionBlock(features,name='tritention_'+str(i))(skip_connections[i],skip_connections[i+1],skip_connections[i-1])\n","        else:\n","            att = AttentionBlock(features,name='attention_'+str(i))(skip_connections[i],skip_connections[i+1])\n","\n","        x = layers.Conv2DTranspose(features,(2,2),strides=(2,2),padding='same')(x)\n","        x = layers.Activation(activation)(x)\n","        x = layers.concatenate([x, att], axis=-1)\n","        x = ConvBlock(features,(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(x)\n","        paramid_up.append(x)\n","        futures_paramid_up.append(features)\n","\n","    # Handle paramid in midle of process.\n","    xm = layers.Conv2D(futures_paramid_down[len(futures_paramid_down) - 1], kernel_size=(1,1),padding='same')(paramid_down[len(futures_paramid_down) - 1])\n","    for index in reversed(range(len(futures_paramid_down) - 1)):\n","        _xm = layers.Conv2D(futures_paramid_down[index], kernel_size=(1,1),padding='same')(paramid_down[index])\n","        xm = layers.Conv2DTranspose(futures_paramid_down[index],(2,2),strides=(2,2),padding='same')(xm)\n","        xm = layers.Add()([xm, _xm])\n","\n","    # Handle paramid in end of process.\n","    xe = layers.Conv2D(futures_paramid_up[0], kernel_size=(1,1),padding='same')(paramid_up[0])\n","    for index in range(1,len(paramid_up)):\n","        _xe = layers.Conv2D(futures_paramid_up[index], kernel_size=(1,1),padding='same')(paramid_up[index])\n","        xe = layers.Conv2DTranspose(futures_paramid_up[index],(2,2),strides=(2,2),padding='same')(xe)\n","        xe = layers.Add()([xe, _xe])\n","\n","    xm = ConvBlock(futures_paramid_down[0],(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(xm)\n","    xe = ConvBlock(futures_paramid_down[0],(3,3),padding='same',activation=activation,dropout=dropout_rate,use_batchnorm=batch_norm)(xe)\n","    conv_final = layers.concatenate([x, xm], axis=-1)\n","    conv_final = layers.concatenate([conv_final, xe], axis=-1)\n","    # Model head\n","    conv_final = layers.Conv2D(num_classes, kernel_size=(1,1),padding='same')(conv_final)\n","    if batch_norm:\n","        conv_final = layers.BatchNormalization(axis=-1)(conv_final)\n","    conv_final = layers.Activation('sigmoid')(conv_final)\n","    model = keras.models.Model(inputs, conv_final, name=name)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"Hs6Bv0FdbWSa"},"source":["# Metrics"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1701862694825,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"qb4MLB12jY3k"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","SMOOTH = 1e-5\n","\n","def _gather_channels(x, indexes, **kwargs):\n","    \"\"\"Slice tensor along channels axis by given indexes\"\"\"\n","    if K.image_data_format() == 'channels_last':\n","        x = K.permute_dimensions(x, (3, 0, 1, 2))\n","        x = K.gather(x, indexes)\n","        x = K.permute_dimensions(x, (1, 2, 3, 0))\n","    else:\n","        x = K.permute_dimensions(x, (1, 0, 2, 3))\n","        x = K.gather(x, indexes)\n","        x = K.permute_dimensions(x, (1, 0, 2, 3))\n","    return\n","\n","def gather_channels(*xs, indexes=None, **kwargs):\n","    \"\"\"Slice tensors along channels axis by given indexes\"\"\"\n","    if indexes is None:\n","        return xs\n","    elif isinstance(indexes, (int)):\n","        indexes = [indexes]\n","    xs = [_gather_channels(x, indexes=indexes, **kwargs) for x in xs]\n","    return xs\n","\n","def get_reduce_axes(per_image, **kwargs):\n","    axes = [1, 2] if K.image_data_format() == 'channels_last' else [2, 3]\n","    if not per_image:\n","        axes.insert(0, 0)\n","    return axes\n","\n","def round_if_needed(x, threshold, **kwargs):\n","    if threshold is not None:\n","        x = K.greater(x, threshold)\n","        x = K.cast(x, K.floatx())\n","    return x\n","\n","\n","def average(x, per_image=False, class_weights=None, **kwargs):\n","    if per_image:\n","        x = K.mean(x, axis=0)\n","    if class_weights is not None:\n","        x = x * class_weights\n","    return K.mean(x)\n","\n","\n","def dice_loss(gt, pr, beta=1, class_weights=1, class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5,\n","            **kwargs):\n","    r\"\"\"The F-score (Dice coefficient) can be interpreted as a weighted average of the precision and recall,\n","    where an F-score reaches its best value at 1 and worst score at 0.\n","    The relative contribution of ``precision`` and ``recall`` to the F1-score are equal.\n","    The formula for the F score is:\n","    .. math:: F_\\beta(precision, recall) = (1 + \\beta^2) \\frac{precision \\cdot recall}\n","        {\\beta^2 \\cdot precision + recall}\n","    The formula in terms of *Type I* and *Type II* errors:\n","    .. math:: F_\\beta(A, B) = \\frac{(1 + \\beta^2) TP} {(1 + \\beta^2) TP + \\beta^2 FN + FP}\n","    where:\n","        TP - true positive;\n","        FP - false positive;\n","        FN - false negative;\n","    Args:\n","        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        class_weights: 1. or list of class weights, len(weights) = C\n","        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.\n","        beta: f-score coefficient\n","        smooth: value to avoid division by zero\n","        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n","            else over whole batch\n","        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round\n","    Returns:\n","        F-score in range [0, 1]\n","    \"\"\"\n","\n","\n","    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n","    pr = round_if_needed(pr, threshold, **kwargs)\n","    axes = get_reduce_axes(per_image, **kwargs)\n","\n","    # calculate score\n","    tp = K.sum(gt * pr, axis=axes)\n","    fp = K.sum(pr, axis=axes) - tp\n","    fn = K.sum(gt, axis=axes) - tp\n","\n","    score = ((1 + beta ** 2) * tp + smooth) \\\n","            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n","    score = average(score, per_image, class_weights, **kwargs)\n","\n","    return 1 - score\n","def dice_score(gt, pr, beta=1, class_weights=1, class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5,\n","            **kwargs):\n","    r\"\"\"The F-score (Dice coefficient) can be interpreted as a weighted average of the precision and recall,\n","    where an F-score reaches its best value at 1 and worst score at 0.\n","    The relative contribution of ``precision`` and ``recall`` to the F1-score are equal.\n","    The formula for the F score is:\n","    .. math:: F_\\beta(precision, recall) = (1 + \\beta^2) \\frac{precision \\cdot recall}\n","        {\\beta^2 \\cdot precision + recall}\n","    The formula in terms of *Type I* and *Type II* errors:\n","    .. math:: F_\\beta(A, B) = \\frac{(1 + \\beta^2) TP} {(1 + \\beta^2) TP + \\beta^2 FN + FP}\n","    where:\n","        TP - true positive;\n","        FP - false positive;\n","        FN - false negative;\n","    Args:\n","        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        class_weights: 1. or list of class weights, len(weights) = C\n","        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.\n","        beta: f-score coefficient\n","        smooth: value to avoid division by zero\n","        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n","            else over whole batch\n","        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round\n","    Returns:\n","        F-score in range [0, 1]\n","    \"\"\"\n","\n","\n","    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n","    pr = round_if_needed(pr, threshold, **kwargs)\n","    axes = get_reduce_axes(per_image, **kwargs)\n","\n","    # calculate score\n","    tp = K.sum(gt * pr, axis=axes)\n","    fp = K.sum(pr, axis=axes) - tp\n","    fn = K.sum(gt, axis=axes) - tp\n","\n","    score = ((1 + beta ** 2) * tp + smooth) \\\n","            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + smooth)\n","    score = average(score, per_image, class_weights, **kwargs)\n","\n","    return score\n","\n","\n","def binary_focal_loss(gt, pr, gamma=2.0, alpha=0.25, **kwargs):\n","    r\"\"\"Implementation of Focal Loss from the paper in binary classification\n","    Formula:\n","        loss = - gt * alpha * ((1 - pr)^gamma) * log(pr) \\\n","               - (1 - gt) * alpha * (pr^gamma) * log(1 - pr)\n","    Args:\n","        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)\n","        alpha: the same as weighting factor in balanced cross entropy, default 0.25\n","        gamma: focusing parameter for modulating factor (1-p), default 2.0\n","    \"\"\"\n","\n","    # clip to prevent NaN's and Inf's\n","    pr = K.clip(pr, K.epsilon(), 1.0 - K.epsilon())\n","\n","    loss_1 = - gt * (alpha * K.pow((1 - pr), gamma) * K.log(pr))\n","    loss_0 = - (1 - gt) * ((1 - alpha) * K.pow((pr), gamma) * K.log(1 - pr))\n","    loss = K.mean(loss_0 + loss_1)\n","    return loss\n","\n","\n","def binary_focal_dice_loss(gt, pr, gamma=2.0, alpha=0.25, beta=1, class_weights=1,\n","                        class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5, **kwargs):\n","\n","    # dice loss\n","    dloss = dice_loss(\n","                    gt,\n","                    pr,\n","                    beta=beta,\n","                    class_weights=class_weights,\n","                    class_indexes=class_indexes,\n","                    smooth=smooth,\n","                    per_image=per_image,\n","                    threshold=threshold\n","                )\n","\n","    # binary focal dice loss\n","    floss = binary_focal_loss(gt, pr, alpha=alpha, gamma=gamma)\n","    return dloss + floss\n","\n","def RVD(gt, pr, gamma=2.0, alpha=0.25, beta=1, class_weights=1,class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5, **kwargs):\n","    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n","    pr = round_if_needed(pr, threshold, **kwargs)\n","\n","    t_gt = K.sum(gt)\n","    t_pr = K.sum(pr)\n","    score = ((t_pr+smooth)/(t_gt+smooth) - 1)\n","    score = average(score, per_image, class_weights, **kwargs)\n","    return score\n","\n","\n","def RVD(gt, pr, gamma=2.0, alpha=0.25, beta=1, class_weights=1,class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5, **kwargs):\n","    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n","    pr = round_if_needed(pr, threshold, **kwargs)\n","\n","    t_gt = K.sum(gt)\n","    t_pr = K.sum(pr)\n","    score = ((t_pr+smooth)/(t_gt+smooth) - 1)\n","    score = average(score, per_image, class_weights, **kwargs)\n","    return score\n","\n","def VOE(gt, pr, beta=1, class_weights=1, class_indexes=None, smooth=SMOOTH, per_image=False, threshold=0.5,\n","            **kwargs):\n","    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n","    pr = round_if_needed(pr, threshold, **kwargs)\n","    axes = get_reduce_axes(per_image, **kwargs)\n","\n","    # calculate score\n","    tp = K.sum(gt * pr, axis=axes)\n","    fp = K.sum(pr, axis=axes) - tp\n","    fn = K.sum(gt, axis=axes) - tp\n","    score = (1. - ( (float(tp) + smooth)/(float(tp+fp+fn) + smooth)))\n","    score = average(score, per_image, class_weights, **kwargs)\n","    return score"]},{"cell_type":"markdown","metadata":{"id":"YemxD2Kt_pC8"},"source":["#MODEL"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":4185,"status":"ok","timestamp":1701848694196,"user":{"displayName":"Huy Đoàn","userId":"04330892056134296543"},"user_tz":-420},"id":"1p3hjU4k_uKv"},"outputs":[],"source":["#Training Paramid Tritention Unet\n","opt=tf.keras.optimizers.Adam(0.0001)\n","input_shape = (128,128,1)\n","model= TP_UNet(input_shape);\n","model.compile(optimizer=opt,loss=[binary_focal_dice_loss],metrics=[dice_score,tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ch9O0hJK_uBf","outputId":"a4f5b88d-8b51-4085-c1e6-6aba5e98c823"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-19-22de0acc01e3>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history  = model.fit_generator(train_loader, validation_data=validate_loader, epochs=100, callbacks = [callback1,callback2])\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","344/344 [==============================] - ETA: 0s - loss: 1.0777 - dice_score: 0.0554 - precision: 0.0222 - recall: 0.9001\n","Epoch 1: val_dice_score improved from -inf to 0.11548, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["344/344 [==============================] - 2910s 8s/step - loss: 1.0777 - dice_score: 0.0554 - precision: 0.0222 - recall: 0.9001 - val_loss: 1.0075 - val_dice_score: 0.1155 - val_precision: 0.0619 - val_recall: 0.9049\n","Epoch 2/100\n","344/344 [==============================] - ETA: 0s - loss: 0.8802 - dice_score: 0.2372 - precision: 0.1137 - recall: 0.7025\n","Epoch 2: val_dice_score did not improve from 0.11548\n","344/344 [==============================] - 321s 933ms/step - loss: 0.8802 - dice_score: 0.2372 - precision: 0.1137 - recall: 0.7025 - val_loss: 1.0778 - val_dice_score: 0.0503 - val_precision: 0.0263 - val_recall: 0.6510\n","Epoch 3/100\n","344/344 [==============================] - ETA: 0s - loss: 0.6492 - dice_score: 0.4569 - precision: 0.3195 - recall: 0.6437\n","Epoch 3: val_dice_score improved from 0.11548 to 0.48177, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 341s 992ms/step - loss: 0.6492 - dice_score: 0.4569 - precision: 0.3195 - recall: 0.6437 - val_loss: 0.6227 - val_dice_score: 0.4818 - val_precision: 0.4736 - val_recall: 0.5126\n","Epoch 4/100\n","344/344 [==============================] - ETA: 0s - loss: 0.5709 - dice_score: 0.5281 - precision: 0.4437 - recall: 0.6550\n","Epoch 4: val_dice_score improved from 0.48177 to 0.54095, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 329s 957ms/step - loss: 0.5709 - dice_score: 0.5281 - precision: 0.4437 - recall: 0.6550 - val_loss: 0.5531 - val_dice_score: 0.5409 - val_precision: 0.5287 - val_recall: 0.5776\n","Epoch 5/100\n","344/344 [==============================] - ETA: 0s - loss: 0.5049 - dice_score: 0.5875 - precision: 0.5308 - recall: 0.6635\n","Epoch 5: val_dice_score improved from 0.54095 to 0.60591, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 331s 962ms/step - loss: 0.5049 - dice_score: 0.5875 - precision: 0.5308 - recall: 0.6635 - val_loss: 0.4872 - val_dice_score: 0.6059 - val_precision: 0.5310 - val_recall: 0.7284\n","Epoch 6/100\n","344/344 [==============================] - ETA: 0s - loss: 0.4308 - dice_score: 0.6551 - precision: 0.6425 - recall: 0.6828\n","Epoch 6: val_dice_score improved from 0.60591 to 0.67966, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 346s 1s/step - loss: 0.4308 - dice_score: 0.6551 - precision: 0.6425 - recall: 0.6828 - val_loss: 0.4033 - val_dice_score: 0.6797 - val_precision: 0.7502 - val_recall: 0.6369\n","Epoch 7/100\n","344/344 [==============================] - ETA: 0s - loss: 0.3821 - dice_score: 0.6981 - precision: 0.7101 - recall: 0.7019\n","Epoch 7: val_dice_score improved from 0.67966 to 0.70113, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 343s 996ms/step - loss: 0.3821 - dice_score: 0.6981 - precision: 0.7101 - recall: 0.7019 - val_loss: 0.3733 - val_dice_score: 0.7011 - val_precision: 0.8672 - val_recall: 0.6047\n","Epoch 8/100\n","344/344 [==============================] - ETA: 0s - loss: 0.3487 - dice_score: 0.7264 - precision: 0.7507 - recall: 0.7194\n","Epoch 8: val_dice_score improved from 0.70113 to 0.73744, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 341s 992ms/step - loss: 0.3487 - dice_score: 0.7264 - precision: 0.7507 - recall: 0.7194 - val_loss: 0.3360 - val_dice_score: 0.7374 - val_precision: 0.8483 - val_recall: 0.6704\n","Epoch 9/100\n","344/344 [==============================] - ETA: 0s - loss: 0.3172 - dice_score: 0.7530 - precision: 0.7903 - recall: 0.7339\n","Epoch 9: val_dice_score improved from 0.73744 to 0.77177, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 338s 982ms/step - loss: 0.3172 - dice_score: 0.7530 - precision: 0.7903 - recall: 0.7339 - val_loss: 0.2944 - val_dice_score: 0.7718 - val_precision: 0.8952 - val_recall: 0.6943\n","Epoch 10/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2888 - dice_score: 0.7768 - precision: 0.8219 - recall: 0.7504\n","Epoch 10: val_dice_score did not improve from 0.77177\n","344/344 [==============================] - 330s 960ms/step - loss: 0.2888 - dice_score: 0.7768 - precision: 0.8219 - recall: 0.7504 - val_loss: 0.3504 - val_dice_score: 0.7125 - val_precision: 0.8494 - val_recall: 0.6311\n","Epoch 11/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2887 - dice_score: 0.7731 - precision: 0.8243 - recall: 0.7404\n","Epoch 11: val_dice_score improved from 0.77177 to 0.79972, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 333s 969ms/step - loss: 0.2887 - dice_score: 0.7731 - precision: 0.8243 - recall: 0.7404 - val_loss: 0.2605 - val_dice_score: 0.7997 - val_precision: 0.8842 - val_recall: 0.7445\n","Epoch 12/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2517 - dice_score: 0.8057 - precision: 0.8614 - recall: 0.7686\n","Epoch 12: val_dice_score improved from 0.79972 to 0.81395, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 327s 949ms/step - loss: 0.2517 - dice_score: 0.8057 - precision: 0.8614 - recall: 0.7686 - val_loss: 0.2425 - val_dice_score: 0.8139 - val_precision: 0.8858 - val_recall: 0.7686\n","Epoch 13/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2425 - dice_score: 0.8113 - precision: 0.8739 - recall: 0.7697\n","Epoch 13: val_dice_score did not improve from 0.81395\n","344/344 [==============================] - 321s 932ms/step - loss: 0.2425 - dice_score: 0.8113 - precision: 0.8739 - recall: 0.7697 - val_loss: 0.2495 - val_dice_score: 0.8032 - val_precision: 0.9187 - val_recall: 0.7293\n","Epoch 14/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2254 - dice_score: 0.8249 - precision: 0.8882 - recall: 0.7801\n","Epoch 14: val_dice_score did not improve from 0.81395\n","344/344 [==============================] - 330s 960ms/step - loss: 0.2254 - dice_score: 0.8249 - precision: 0.8882 - recall: 0.7801 - val_loss: 0.2467 - val_dice_score: 0.8003 - val_precision: 0.9456 - val_recall: 0.7119\n","Epoch 15/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2232 - dice_score: 0.8240 - precision: 0.8949 - recall: 0.7742\n","Epoch 15: val_dice_score improved from 0.81395 to 0.81926, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 341s 992ms/step - loss: 0.2232 - dice_score: 0.8240 - precision: 0.8949 - recall: 0.7742 - val_loss: 0.2295 - val_dice_score: 0.8193 - val_precision: 0.8396 - val_recall: 0.8178\n","Epoch 16/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2135 - dice_score: 0.8307 - precision: 0.9033 - recall: 0.7793\n","Epoch 16: val_dice_score did not improve from 0.81926\n","344/344 [==============================] - 322s 935ms/step - loss: 0.2135 - dice_score: 0.8307 - precision: 0.9033 - recall: 0.7793 - val_loss: 0.2665 - val_dice_score: 0.7759 - val_precision: 0.9577 - val_recall: 0.6714\n","Epoch 17/100\n","344/344 [==============================] - ETA: 0s - loss: 0.2076 - dice_score: 0.8339 - precision: 0.9088 - recall: 0.7807\n","Epoch 17: val_dice_score improved from 0.81926 to 0.82211, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 331s 963ms/step - loss: 0.2076 - dice_score: 0.8339 - precision: 0.9088 - recall: 0.7807 - val_loss: 0.2186 - val_dice_score: 0.8221 - val_precision: 0.9239 - val_recall: 0.7582\n","Epoch 18/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1953 - dice_score: 0.8434 - precision: 0.9194 - recall: 0.7881\n","Epoch 18: val_dice_score improved from 0.82211 to 0.82551, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 362s 1s/step - loss: 0.1953 - dice_score: 0.8434 - precision: 0.9194 - recall: 0.7881 - val_loss: 0.2118 - val_dice_score: 0.8255 - val_precision: 0.9094 - val_recall: 0.7730\n","Epoch 19/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1953 - dice_score: 0.8411 - precision: 0.9222 - recall: 0.7818\n","Epoch 19: val_dice_score did not improve from 0.82551\n","344/344 [==============================] - 330s 960ms/step - loss: 0.1953 - dice_score: 0.8411 - precision: 0.9222 - recall: 0.7818 - val_loss: 0.2259 - val_dice_score: 0.8090 - val_precision: 0.9623 - val_recall: 0.7126\n","Epoch 20/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1853 - dice_score: 0.8486 - precision: 0.9294 - recall: 0.7893\n","Epoch 20: val_dice_score improved from 0.82551 to 0.83861, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 331s 961ms/step - loss: 0.1853 - dice_score: 0.8486 - precision: 0.9294 - recall: 0.7893 - val_loss: 0.1943 - val_dice_score: 0.8386 - val_precision: 0.9222 - val_recall: 0.7867\n","Epoch 21/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1831 - dice_score: 0.8488 - precision: 0.9318 - recall: 0.7881\n","Epoch 21: val_dice_score did not improve from 0.83861\n","344/344 [==============================] - 378s 1s/step - loss: 0.1831 - dice_score: 0.8488 - precision: 0.9318 - recall: 0.7881 - val_loss: 0.1953 - val_dice_score: 0.8353 - val_precision: 0.9555 - val_recall: 0.7586\n","Epoch 22/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1762 - dice_score: 0.8536 - precision: 0.9383 - recall: 0.7906\n","Epoch 22: val_dice_score improved from 0.83861 to 0.84933, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 342s 995ms/step - loss: 0.1762 - dice_score: 0.8536 - precision: 0.9383 - recall: 0.7906 - val_loss: 0.1788 - val_dice_score: 0.8493 - val_precision: 0.9208 - val_recall: 0.8038\n","Epoch 23/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1802 - dice_score: 0.8478 - precision: 0.9362 - recall: 0.7828\n","Epoch 23: val_dice_score did not improve from 0.84933\n","344/344 [==============================] - 331s 961ms/step - loss: 0.1802 - dice_score: 0.8478 - precision: 0.9362 - recall: 0.7828 - val_loss: 0.1823 - val_dice_score: 0.8440 - val_precision: 0.9472 - val_recall: 0.7784\n","Epoch 24/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1692 - dice_score: 0.8569 - precision: 0.9445 - recall: 0.7919\n","Epoch 24: val_dice_score did not improve from 0.84933\n","344/344 [==============================] - 322s 935ms/step - loss: 0.1692 - dice_score: 0.8569 - precision: 0.9445 - recall: 0.7919 - val_loss: 0.1841 - val_dice_score: 0.8418 - val_precision: 0.9511 - val_recall: 0.7713\n","Epoch 25/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1721 - dice_score: 0.8523 - precision: 0.9433 - recall: 0.7856\n","Epoch 25: val_dice_score improved from 0.84933 to 0.85071, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 333s 968ms/step - loss: 0.1721 - dice_score: 0.8523 - precision: 0.9433 - recall: 0.7856 - val_loss: 0.1744 - val_dice_score: 0.8507 - val_precision: 0.9329 - val_recall: 0.8000\n","Epoch 26/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1663 - dice_score: 0.8565 - precision: 0.9486 - recall: 0.7888\n","Epoch 26: val_dice_score did not improve from 0.85071\n","344/344 [==============================] - 330s 960ms/step - loss: 0.1663 - dice_score: 0.8565 - precision: 0.9486 - recall: 0.7888 - val_loss: 0.1842 - val_dice_score: 0.8377 - val_precision: 0.9665 - val_recall: 0.7558\n","Epoch 27/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1622 - dice_score: 0.8591 - precision: 0.9514 - recall: 0.7916\n","Epoch 27: val_dice_score did not improve from 0.85071\n","344/344 [==============================] - 329s 957ms/step - loss: 0.1622 - dice_score: 0.8591 - precision: 0.9514 - recall: 0.7916 - val_loss: 0.1879 - val_dice_score: 0.8323 - val_precision: 0.9693 - val_recall: 0.7460\n","Epoch 28/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1815 - dice_score: 0.8388 - precision: 0.9449 - recall: 0.7623\n","Epoch 28: val_dice_score did not improve from 0.85071\n","344/344 [==============================] - 329s 958ms/step - loss: 0.1815 - dice_score: 0.8388 - precision: 0.9449 - recall: 0.7623 - val_loss: 0.1919 - val_dice_score: 0.8290 - val_precision: 0.8630 - val_recall: 0.8161\n","Epoch 29/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1787 - dice_score: 0.8403 - precision: 0.9471 - recall: 0.7632\n","Epoch 29: val_dice_score did not improve from 0.85071\n","344/344 [==============================] - 321s 932ms/step - loss: 0.1787 - dice_score: 0.8403 - precision: 0.9471 - recall: 0.7632 - val_loss: 0.1878 - val_dice_score: 0.8304 - val_precision: 0.9660 - val_recall: 0.7442\n","Epoch 30/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1585 - dice_score: 0.8589 - precision: 0.9563 - recall: 0.7872\n","Epoch 30: val_dice_score did not improve from 0.85071\n","344/344 [==============================] - 322s 935ms/step - loss: 0.1585 - dice_score: 0.8589 - precision: 0.9563 - recall: 0.7872 - val_loss: 0.1679 - val_dice_score: 0.8490 - val_precision: 0.9610 - val_recall: 0.7774\n","Epoch 31/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1521 - dice_score: 0.8641 - precision: 0.9596 - recall: 0.7936\n","Epoch 31: val_dice_score improved from 0.85071 to 0.85961, saving model to /content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\n","344/344 [==============================] - 342s 994ms/step - loss: 0.1521 - dice_score: 0.8641 - precision: 0.9596 - recall: 0.7936 - val_loss: 0.1560 - val_dice_score: 0.8596 - val_precision: 0.9508 - val_recall: 0.8016\n","Epoch 32/100\n","344/344 [==============================] - ETA: 0s - loss: 0.1496 - dice_score: 0.8655 - precision: 0.9610 - recall: 0.7944\n","Epoch 32: val_dice_score did not improve from 0.85961\n","344/344 [==============================] - 322s 936ms/step - loss: 0.1496 - dice_score: 0.8655 - precision: 0.9610 - recall: 0.7944 - val_loss: 0.1562 - val_dice_score: 0.8580 - val_precision: 0.9573 - val_recall: 0.7925\n","Epoch 33/100\n","113/344 [========>.....................] - ETA: 3:28 - loss: 0.1461 - dice_score: 0.8684 - precision: 0.9633 - recall: 0.7980"]}],"source":["from keras.callbacks import ModelCheckpoint\n","filepath1 = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_best.hdf5\"\n","filepath2 = \"/content/drive/MyDrive/Liver Segmentation/LTS_NewData/Weight/1_TPUnet_end.hdf5\"\n","callback1 = ModelCheckpoint(filepath1, monitor='val_dice_score', verbose=1, save_best_only=True,mode='max')\n","callback2 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","history  = model.fit_generator(train_loader, validation_data=validate_loader, epochs=100, callbacks = [callback1,callback2])\n","model.save_weights(filepath2)\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"IUtlRGCMJTOS"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
